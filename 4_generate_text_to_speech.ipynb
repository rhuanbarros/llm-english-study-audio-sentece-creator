{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xvector containing speaker's voice characteristics from a dataset\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Sentences_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wizard-Lesson 1-01.wma</td>\n",
       "      <td>Conversation, Lesson 1\\n-separator-\\nDid the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wizard-Lesson 10-10.wma</td>\n",
       "      <td>Conversation, Lesson #10\\n-separator-\\nIs he a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wizard-Lesson 11-11.wma</td>\n",
       "      <td>Conversation, Lesson 11\\n-separator-\\nWhere do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wizard-Lesson 12-12.wma</td>\n",
       "      <td>Conversation, Lesson 12  \\n-separator-  \\nShe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wizard-Lesson 13-13.wma</td>\n",
       "      <td>Conversation, Lesson 13\\n-separator-\\nHe assig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wizard-Lesson 14-14.wma</td>\n",
       "      <td>Conversation Lesson 14\\n-separator-\\nShe deplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wizard-Lesson 14-14.wma</td>\n",
       "      <td>Conversation  Lesson 14\\n-separator-\\nHe deplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wizard-Lesson 15-15.wma</td>\n",
       "      <td>Conversation, Lesson 15  \\n-separator-  \\nTher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wizard-Lesson 16-16.wma</td>\n",
       "      <td>Conversation Lesson 16\\n-separator-\\nIs there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wizard-Lesson 17-17.wma</td>\n",
       "      <td>Conversation, Lesson 17\\n-separator-\\nAre ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wizard-Lesson 18-18.wma</td>\n",
       "      <td>Conversation  Lesson 18\\n-separator-\\nAre ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wizard-Lesson 19-19.wma</td>\n",
       "      <td>Conversation  Lesson 19\\n-separator-\\nWhat did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wizard-Lesson 2-02.wma</td>\n",
       "      <td>Wizard Book 3 Conversation  \\nLesson 2  \\n-sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wizard-Lesson 20-20.wma</td>\n",
       "      <td>Conversation, Lesson 20\\n-separator-\\nHe alway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wizard-Lesson 21-21.wma</td>\n",
       "      <td>Conversation, Lesson 21  \\n-separator-  \\nI'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wizard-Lesson 22-22.wma</td>\n",
       "      <td>Lesson 22\\n-separator-\\nThe developer can assi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wizard-Lesson 23-23.wma</td>\n",
       "      <td>Conversation Lesson 23\\n-separator-\\nShould we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wizard-Lesson 24-24.wma</td>\n",
       "      <td>Conversation  Lesson 24\\n-separator-\\nHe shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wizard-Lesson 25-25.wma</td>\n",
       "      <td>Conversation Lesson 25\\n-separator-\\nThe devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wizard-Lesson 26-26.wma</td>\n",
       "      <td>Conversation, Lesson 26\\n-separator-\\nWhen wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wizard-Lesson 27-27.wma</td>\n",
       "      <td>Conversation Lesson 27\\n-separator-\\nShe would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wizard-Lesson 28-28.wma</td>\n",
       "      <td>Conversation, Lesson 28\\n-separator-\\nThe deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wizard-Lesson 29-29.wma</td>\n",
       "      <td>Conversation, Lesson 29\\n-separator-\\nWhat are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wizard-Lesson 3-03.wma</td>\n",
       "      <td>Conversation, Lesson 3  \\n-separator-  \\nWhat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Wizard-Lesson 30-30.wma</td>\n",
       "      <td>Conversation Lesson 30\\n-separator-\\nThe devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wizard-Lesson 4-04.wma</td>\n",
       "      <td>Conversation  Lesson 4\\n-separator-\\nWhat did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wizard-Lesson 5-05.wma</td>\n",
       "      <td>Conversation, Lesson 5\\n-separator-\\nHe attend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wizard-Lesson 6-06.wma</td>\n",
       "      <td>Conversation, Lesson six\\n-separator-\\nDid she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wizard-Lesson 7-07.wma</td>\n",
       "      <td>Conversation, Lesson 7  \\n-separator-  \\nThey ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wizard-Lesson 8-08.wma</td>\n",
       "      <td>Conversation. Lesson 8.\\n-separator-\\nThey dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Wizard-Lesson 9-09.wma</td>\n",
       "      <td>Conversation, Lesson 9\\n-separator-\\nThe devel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Filename                                      Sentences_new\n",
       "0    Wizard-Lesson 1-01.wma  Conversation, Lesson 1\\n-separator-\\nDid the d...\n",
       "1   Wizard-Lesson 10-10.wma  Conversation, Lesson #10\\n-separator-\\nIs he a...\n",
       "2   Wizard-Lesson 11-11.wma  Conversation, Lesson 11\\n-separator-\\nWhere do...\n",
       "3   Wizard-Lesson 12-12.wma  Conversation, Lesson 12  \\n-separator-  \\nShe ...\n",
       "4   Wizard-Lesson 13-13.wma  Conversation, Lesson 13\\n-separator-\\nHe assig...\n",
       "5   Wizard-Lesson 14-14.wma  Conversation Lesson 14\\n-separator-\\nShe deplo...\n",
       "6   Wizard-Lesson 14-14.wma  Conversation  Lesson 14\\n-separator-\\nHe deplo...\n",
       "7   Wizard-Lesson 15-15.wma  Conversation, Lesson 15  \\n-separator-  \\nTher...\n",
       "8   Wizard-Lesson 16-16.wma  Conversation Lesson 16\\n-separator-\\nIs there ...\n",
       "9   Wizard-Lesson 17-17.wma  Conversation, Lesson 17\\n-separator-\\nAre ther...\n",
       "10  Wizard-Lesson 18-18.wma  Conversation  Lesson 18\\n-separator-\\nAre ther...\n",
       "11  Wizard-Lesson 19-19.wma  Conversation  Lesson 19\\n-separator-\\nWhat did...\n",
       "12   Wizard-Lesson 2-02.wma  Wizard Book 3 Conversation  \\nLesson 2  \\n-sep...\n",
       "13  Wizard-Lesson 20-20.wma  Conversation, Lesson 20\\n-separator-\\nHe alway...\n",
       "14  Wizard-Lesson 21-21.wma  Conversation, Lesson 21  \\n-separator-  \\nI'm ...\n",
       "15  Wizard-Lesson 22-22.wma  Lesson 22\\n-separator-\\nThe developer can assi...\n",
       "16  Wizard-Lesson 23-23.wma  Conversation Lesson 23\\n-separator-\\nShould we...\n",
       "17  Wizard-Lesson 24-24.wma  Conversation  Lesson 24\\n-separator-\\nHe shoul...\n",
       "18  Wizard-Lesson 25-25.wma  Conversation Lesson 25\\n-separator-\\nThe devel...\n",
       "19  Wizard-Lesson 26-26.wma  Conversation, Lesson 26\\n-separator-\\nWhen wil...\n",
       "20  Wizard-Lesson 27-27.wma  Conversation Lesson 27\\n-separator-\\nShe would...\n",
       "21  Wizard-Lesson 28-28.wma  Conversation, Lesson 28\\n-separator-\\nThe deve...\n",
       "22  Wizard-Lesson 29-29.wma  Conversation, Lesson 29\\n-separator-\\nWhat are...\n",
       "23   Wizard-Lesson 3-03.wma  Conversation, Lesson 3  \\n-separator-  \\nWhat ...\n",
       "24  Wizard-Lesson 30-30.wma  Conversation Lesson 30\\n-separator-\\nThe devel...\n",
       "25   Wizard-Lesson 4-04.wma  Conversation  Lesson 4\\n-separator-\\nWhat did ...\n",
       "26   Wizard-Lesson 5-05.wma  Conversation, Lesson 5\\n-separator-\\nHe attend...\n",
       "27   Wizard-Lesson 6-06.wma  Conversation, Lesson six\\n-separator-\\nDid she...\n",
       "28   Wizard-Lesson 7-07.wma  Conversation, Lesson 7  \\n-separator-  \\nThey ...\n",
       "29   Wizard-Lesson 8-08.wma  Conversation. Lesson 8.\\n-separator-\\nThey dep...\n",
       "30   Wizard-Lesson 9-09.wma  Conversation, Lesson 9\\n-separator-\\nThe devel..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"transcript_new_sentences.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Wizard-Lesson 1-01\n",
      "Did the developer deploy the new feature to the server?\n",
      "Yes, he did. He deployed the new feature to the server.\n",
      "No, he didn't. He didn't deploy the new feature to the server.\n",
      "Did the project manager update the task list on the board?\n",
      "No, she didn't. She didn't update the task list on the board.\n",
      "Did you fetch the data from the database?\n",
      "Yes, I did. I fetched the data from the database.\n",
      "Did your colleague complete the coding tasks ahead of schedule?\n",
      "Yes, she did. She completed the coding tasks ahead of schedule.\n",
      "No, she didn't. She didn't complete the coding tasks ahead of schedule.\n",
      "Did they implement a new algorithm in the machine learning model?\n",
      "No, they didn't. They didn't implement a new algorithm in the machine learning model.\n",
      "Is your fellow programmer debugging the code in the office?\n",
      "Yes, he is. He is debugging the code in the office.\n",
      "No, he isn't. He isn't debugging the code in the office.\n",
      "Are the interns testing the software in the virtual environment?\n",
      "Yes, they are. They are testing the software in the virtual environment.\n",
      "No, they aren't. They aren't testing the software in the virtual environment.\n",
      "Is your son organizing the tools in the workshop?\n",
      "Yes, he is. He is organizing the tools in the workshop.\n",
      "No, he isn't. He isn't organizing the tools in the workshop.\n",
      "Is Jane updating her code repository every day?\n",
      "Yes, she is. She is updating her code repository every day.\n",
      "No, she isn't. She isn't updating her code repository every day.\n",
      "Is the engineer processing the data for the machine learning model?\n",
      "Yes, he is. He is processing the data for the machine learning model.\n",
      "No, he isn't. He is not processing the data for the machine learning model.\n",
      "1 Wizard-Lesson 10-10\n",
      "Is he a junior developer or a senior developer?\n",
      "He is a junior developer.\n",
      "How many years of experience do you think she has?\n",
      "I think she has 10 years of experience.\n",
      "What task were they working on?\n",
      "I think they were debugging their code.\n",
      "Who is the least experienced programmer in your team?\n",
      "I think Karen is the least experienced.\n",
      "Who is the most experienced developer in your team?\n",
      "I think Mark is the most experienced.\n",
      "What is the most challenging project in the company?\n",
      "I think it's the machine learning project.\n",
      "What is the simplest task in programming?\n",
      "I think it's setting up a new development environment.\n",
      "When should we schedule the next sprint planning meeting?\n",
      "What about 10 o'clock in the morning?\n",
      "Which is the most efficient programming language you know?\n",
      "What about Python?\n",
      "What is the largest database system you have worked with?\n",
      "What about MongoDB?\n",
      "2 Wizard-Lesson 11-11\n",
      "Where does the developer come from?\n",
      "I believe he hails from England.\n",
      "I doubt he hails from England.\n",
      "Where do the programmers come from?\n",
      "I think they originate from Italy.\n",
      "I doubt they originate from Italy.\n",
      "Do you know where the project manager comes from?\n",
      "I think she's from New York.\n",
      "Do you know where the data scientist comes from?\n",
      "I think he's from Utah.\n",
      "Where is the software team from?\n",
      "I think they are from Germany.\n",
      "Where is the software engineer from?\n",
      "I think she's from Spain.\n",
      "Do you think junior developers code too fast?\n",
      "I think they do.\n",
      "But some junior developers don't code too fast.\n",
      "Do you think the machine learning course is too expensive?\n",
      "I think it is, but some machine learning courses are not too expensive.\n",
      "Do you think it's too cold to debug outside?\n",
      "I think it is.\n",
      "But I don't think it's too cold to debug outside.\n",
      "Do you think the coding challenge was too difficult?\n",
      "I think it was.\n",
      "But I don't think the coding challenge was too difficult for the programmers.\n",
      "3 Wizard-Lesson 12-12\n",
      "  \n",
      "She stashed her sunglasses in her bag.  \n",
      "How do you know she stashed them in her bag?  \n",
      "I observed her stashing them in her bag.  \n",
      "  \n",
      "He opted for a shuttle to reach the airport.  \n",
      "How do you know that he chose a shuttle?  \n",
      "I witnessed him opting for the shuttle.  \n",
      "  \n",
      "She avoids air travel out of fear.  \n",
      "How do you know that?  \n",
      "Because she consistently opts for train travel.  \n",
      "  \n",
      "The administrative assistant departed the premises a few minutes ago.  \n",
      "How do you know that?  \n",
      "I witnessed her departing the office.  \n",
      "  \n",
      "He dispatched the document via email.  \n",
      "  \n",
      "She's too fatigued to engage in physical activity today.  \n",
      "How do you know she's too fatigued?  \n",
      "She toiled until late last night.  \n",
      "  \n",
      "This assignment exceeds her capabilities.  \n",
      "How do you know this assignment exceeds her capabilities?  \n",
      "Because she lacks prior experience in this department.  \n",
      "  \n",
      "She's too preoccupied to attend tonight's gathering.  \n",
      "How do you know she's too preoccupied tonight?  \n",
      "Because she has an examination at school.  \n",
      "  \n",
      "She's underage to be out late.  \n",
      "Why do you say she's underage?  \n",
      "She's merely 14 years old.  \n",
      "  \n",
      "He's too unwell to report to work.  \n",
      "Why do you say he's too unwell to report to work?  \n",
      "Because he was confined to bed yesterday.  \n",
      "4 Wizard-Lesson 13-13\n",
      "He assigned the task to Sandy, but she didn't start it. What's the issue with her?\n",
      "I think she's occupied with other projects.\n",
      "I submitted the code for review, but no one provided feedback. What's the issue with the code?\n",
      "I think there might be a bug. I submitted the code for review, but no one provided feedback. What's the issue with the code?\n",
      "I think the team was focused on another task.\n",
      "He didn't attend the team meeting. What's the issue with him?\n",
      "I think he is feeling under the weather.\n",
      "She was supposed to present the project, but she didn't show up. What's the issue with her?\n",
      "I think she had a last-minute client meeting.\n",
      "Mr. Johnson's code structure is too complicated. Who designed it for him? It was outsourced. The code structure is too complicated. Who designed it for him? It was outsourced.\n",
      "Alice's API documentation was missing key details. How do you know that? I observed her creating it.\n",
      "I overlooked the sprint planning session. How did you manage to overlook it?\n",
      "I don't know how it slipped my mind.\n",
      "I misplaced the software architecture diagram. How did you lose track of it?\n",
      "I don't know how it slipped my mind.\n",
      "I neglected to push the latest changes to the repository. How did you overlook it?\n",
      "I accidentally closed my IDE without pushing the changes.\n",
      "I always struggle to recall her API endpoint. Why do you find it hard to remember it?\n",
      "5 Wizard-Lesson 14-14\n",
      "She deployed her code in the repository.\n",
      "Are you sure she did that?\n",
      "Yes, I am. She deployed her code in the repository.\n",
      "There is a new pull request for you on GitHub.\n",
      "Are you sure of that?\n",
      "Yes, I am. I saw it on your GitHub repository.\n",
      "Are you sure of that? Yes, I am. I saw it on your GitHub repository.\n",
      "She pushed all her commits to the master branch.\n",
      "Are you sure she did?\n",
      "Yes, I am. She pushed all her commits to the master branch.\n",
      "The algorithm was implemented in his project last week.\n",
      "Are you sure of that?\n",
      "Yes, I am. The algorithm was implemented in his project last week.\n",
      "She merged her feature branch into the main codebase.\n",
      "Are you sure she did?\n",
      "Yes, I am. She merged her feature branch into the main codebase.\n",
      "His IDE is not responding.\n",
      "Are you sure it's not working?\n",
      "Yes, I am. His IDE is not responding.\n",
      "Amy's QA team tests her application every Friday.\n",
      "Are you sure they test it?\n",
      "Yes, I am. Amy's QA team tests her application every Friday.\n",
      "The server's database is full of entries.\n",
      "Are you sure it is?\n",
      "Yes, I am. The server's database is full of entries.\n",
      "John's mentor assigned him a challenging project.\n",
      "Are you sure he did?\n",
      "Yes, I am. John's mentor assigned him a challenging project.\n",
      "My colleague's backlog is empty.\n",
      "Are you sure it is?\n",
      "Yes, I am. My colleague's backlog is empty.\n",
      "6 Wizard-Lesson 14-14\n",
      "He deployed his code in the repository.\n",
      "Are you sure he did that?\n",
      "Yes, I am.\n",
      "There is a new task for you in your project.\n",
      "Are you sure of that?\n",
      "Yes, I am. I checked it in your project.\n",
      "Are you sure of that?\n",
      "Yes, I am.\n",
      "I confirmed it in your project.\n",
      "She assigned all the tickets to the developers.\n",
      "Are you sure she did?\n",
      "Yes, I am.\n",
      "I was with her when she assigned them.\n",
      "The algorithm was implemented in the system last week.\n",
      "Are you sure of that?\n",
      "Yes, I am. I was testing it when it was implemented.\n",
      "He pushed the updated model to the server.\n",
      "Are you sure he did?\n",
      "Yes, I am. I observed the process.\n",
      "The server is not responding.\n",
      "Are you sure it's not responding?\n",
      "Yes, I am. I was trying to connect when it stopped responding.\n",
      "The project manager schedules a meeting every Monday.\n",
      "Are you sure they schedule it?\n",
      "Yes, I am. I always receive the meeting invites.\n",
      "The software's requirements are well-defined.\n",
      "Are you sure they are?\n",
      "Yes, I am. I just reviewed them.\n",
      "The developer's IDE crashed during the presentation.\n",
      "Are you sure it happened?\n",
      "Yes, I am. I was there when it crashed.\n",
      "7 Wizard-Lesson 15-15\n",
      "  \n",
      "There's a colleague positioned near the entrance.  \n",
      "Who is he? He's the fresh recruit in logistics.  \n",
      "  \n",
      "There's a portrait of the team in the boardroom.  \n",
      "Who captured that image? Suited up with her new DSLR.  \n",
      "  \n",
      "Someone's anticipating your arrival.  \n",
      "Who could it be? I suspect it's your newly assigned mentor.  \n",
      "  \n",
      "There's a camera stowed in the backpack.  \n",
      "Who stashed it there? I believe Sam did.  \n",
      "  \n",
      "There's a dossier in the portfolio.  \n",
      "Who placed it there? I witnessed the administrative assistant placing it in the portfolio.  \n",
      "  \n",
      "There was a padlock securing the garage entry.  \n",
      "Who installed the padlock on the garage door? I believe it was the housekeeper.  \n",
      "  \n",
      "There was a homemade cake in the chiller.  \n",
      "Who whipped up the cake? My mom did.  \n",
      "  \n",
      "There was a pupil in the lecture hall.  \n",
      "Who was he? He was the instructor's offspring.  \n",
      "  \n",
      "There was a lady attending the conference.  \n",
      "Who was she? She's the new financial institution executive.  \n",
      "  \n",
      "There was an advertisement in the periodical.  \n",
      "Who placed this advertisement in the publication? James did.  \n",
      "8 Wizard-Lesson 16-16\n",
      "Is there a security lock on the server?\n",
      "Yes, there is.\n",
      "But I don't think there is.\n",
      "Do you know if there is data corruption in the system?\n",
      "I think there is.\n",
      "I don't think there is.\n",
      "I don't think there is.\n",
      "Is there a lock on the code repository?\n",
      "Yes, I think there is.\n",
      "Sorry, I just checked and there isn't.\n",
      "Is there code in the repository?\n",
      "Yes, I think there is.\n",
      "Sorry, I checked and there isn't.\n",
      "Is there a solution to this coding issue?\n",
      "I am sure there is a solution.\n",
      "I am afraid there isn't a solution to this problem.\n",
      "I am afraid there isn't a solution to this problem.\n",
      "Was there an update on the programming language for me?\n",
      "I am sure there was an update for you.\n",
      "I don't think there was an update.\n",
      "Is there anybody in the development room?\n",
      "I don't know if there is or there is not.\n",
      "I think there is somebody in there.\n",
      "Is there some debugging tool in the development environment?\n",
      "I am afraid there isn't any debugging tool here.\n",
      "I think there is some.\n",
      "Was there a senior developer with her during the project?\n",
      "Yes, there was.\n",
      "But I didn't see any senior developer while I was there.\n",
      "Was there a code review in the sprint?\n",
      "I'm not sure there was.\n",
      "I don't sure there was.\n",
      "I don't think there was.\n",
      "9 Wizard-Lesson 17-17\n",
      "Are there developers here?\n",
      "Yes, there are. They're in the meeting room.\n",
      "No, there aren't. They've all left for another project.\n",
      "How many algorithms are there in your machine learning model?\n",
      "I really don't know how many algorithms there are. I think there are more than 20.\n",
      "How many data points are there in your dataset?\n",
      "I really don't know how many data points there are. I think there are more than 30.\n",
      "How many lines of code are there in this software project?\n",
      "I really don't know how many lines of code there are. I think there are more than 40.\n",
      "How many functions are there in the software library?\n",
      "I really don't know how many functions there are. I think there are more than 1,000.\n",
      "How many users were there on the platform?\n",
      "I really don't know how many users there were. I think there were more than 10,000.\n",
      "How many developers were there at the hackathon?\n",
      "I really don't know how many developers there were. I don't think there were more than 100.\n",
      "How many testers were there at the QA session?\n",
      "I really don't know how many testers there were. I think there weren't more than 50.\n",
      "How many bugs were there in the code review yesterday?\n",
      "I really don't know how many bugs there were. I think there weren't more than 40.\n",
      "How many stakeholders were there in the project meeting?\n",
      "I really don't know how many stakeholders there were. I think there weren't more than 100.\n",
      "10 Wizard-Lesson 18-18\n",
      "Are there any pending tasks in the sprint backlog?\n",
      "Yes, there are. There are pending tasks in the sprint backlog.\n",
      "Are there many bugs in the code?\n",
      "Yes, there are. There are many bugs in the code.\n",
      "There are many bugs in the code.\n",
      "There are many bugs in the code.\n",
      "There are many bugs in the code.\n",
      "There are many bugs in the code?\n",
      "Yes, there are. There are many bugs in the code.\n",
      "Are there any snacks in the break room?\n",
      "No, there aren't. There aren't any snacks in the break room.\n",
      "Are there any unit tests in the codebase?\n",
      "No, there aren't. There aren't any unit tests in the codebase.\n",
      "Are there many developers in the project team?\n",
      "Yes, there are. There are many developers in the project team.\n",
      "Were there many features in the previous release?\n",
      "Yes, there were. There were many features in the previous release.\n",
      "Were there many attendees in the last meeting?\n",
      "No, there weren't. There weren't many attendees in the last meeting.\n",
      "Were there any notes in the meeting minutes?\n",
      "No, there were. There were many kids at the swimming pool.\n",
      "Were there many commits in the last week?\n",
      "Yes, there were.\n",
      "Were there many engineers in the last hackathon?\n",
      "Yes, there were.\n",
      "Were there many engineers in the last hackathon?\n",
      "Yes, there were.\n",
      "There were many commits in the last week.\n",
      "11 Wizard-Lesson 19-19\n",
      "What did he deploy?\n",
      "He deployed the new machine learning model to production.\n",
      "Did he deploy the new machine learning model to production?\n",
      "Yes, he did.\n",
      "What did you do?\n",
      "I debugged the code for the new feature.\n",
      "Did you debug the code for the new feature?\n",
      "Yes, I did.\n",
      "What did she do with the project?\n",
      "She pushed the project to the remote repository.\n",
      "Did she push the project to the remote repository?\n",
      "Yes, she did.\n",
      "How did he send the data?\n",
      "He sent the data via the REST API.\n",
      "Did he send the data via the REST API?\n",
      "Yes, he did.\n",
      "Where did they review the code?\n",
      "They reviewed the code in the code review meeting.\n",
      "Did they review the code in the code review meeting?\n",
      "Yes, they did.\n",
      "These requirements are from the same project.\n",
      "Did they review the code in the code review meeting?\n",
      "Yes, they did.\n",
      "These requirements are for the new feature.\n",
      "Are these requirements for the new feature?\n",
      "Yes, they are.\n",
      "This task is hers.\n",
      "Is this task hers?\n",
      "Yes, it is.\n",
      "This bug is his.\n",
      "Is this bug his?\n",
      "Yes, it is.\n",
      "This ticket is mine.\n",
      "Is this ticket yours?\n",
      "Yes, it is.\n",
      "This issue isn't mine.\n",
      "Isn't this issue yours?\n",
      "No, it isn't.\n",
      "12 Wizard-Lesson 2-02\n",
      "Lesson 2  \n",
      "  \n",
      "Where did the engineer deploy the algorithm?  \n",
      "The engineer deployed the algorithm on the server.  \n",
      "No, he didn't. He didn't deploy the algorithm on the server.  \n",
      "  \n",
      "When did the developers test the code?  \n",
      "They tested the code during the sprint.  \n",
      "No, they didn't. They didn't test the code during the sprint.  \n",
      "  \n",
      "When did the programmer optimize the database?  \n",
      "He optimized the database last week.  \n",
      "No, he didn't. He didn't optimize the database last week.  \n",
      "  \n",
      "Where did you store the project files?  \n",
      "I stored the project files in the cloud.  \n",
      "No, you didn't. You didn't store the project files in the cloud.  \n",
      "  \n",
      "Who debugged your software?  \n",
      "My colleague debugged my software.  \n",
      "No, she didn't. Your colleague didn't debug your software.  \n",
      "  \n",
      "Who is running the machine learning model right now?  \n",
      "The data scientist is running the machine learning model right now.  \n",
      "No, she isn't. She is not running the machine learning model right now.  \n",
      "  \n",
      "Who is coding the new feature?  \n",
      "The junior developer is coding the new feature.  \n",
      "No, he isn't. He is not coding the new feature.  \n",
      "  \n",
      "Who is struggling with Git conflicts?  \n",
      "I'm struggling with Git conflicts.  \n",
      "No, you aren't. You are not struggling with Git conflicts.  \n",
      "  \n",
      "Who implemented the neural network architecture?  \n",
      "The team lead implemented the neural network architecture.  \n",
      "No, they didn't. They didn't implement the neural network architecture.  \n",
      "  \n",
      "Who is sponsoring your machine learning certification?  \n",
      "My company is sponsoring my machine learning certification.  \n",
      "No, it isn't. Your company isn't sponsoring your machine learning certification.  \n",
      "13 Wizard-Lesson 20-20\n",
      "He always goes for a run with his dog.\n",
      "I didn't realize that he always went for a run with his dog.\n",
      "Yes, he does. He goes for a run every morning.\n",
      "She handles phone calls in Spanish and English.\n",
      "I didn't know that she handled phone calls in Spanish and English.\n",
      "Yes, she does. She can speak both languages fluently.\n",
      "Developers enjoy using peanut butter.\n",
      "I didn't know that they enjoyed using peanut butter.\n",
      "Yes, they do. They often use peanut butter while working on projects.\n",
      "Some programmers bring a peanut butter and jelly sandwich to work.\n",
      "I didn't realize that they enjoyed it so much.\n",
      "Yes, they do. They bring it to work for lunch.\n",
      "I transmitted the images via email.\n",
      "I wasn't aware that you transmitted them via email.\n",
      "Yes, I did. I sent them through email.\n",
      "I'm not sure if the code executed. Did it execute or not?\n",
      "Unfortunately, it didn't execute.\n",
      "I'm not sure if the algorithm ran. Did it run or not?\n",
      "Unfortunately, it didn't run.\n",
      "I'm not sure if she contacted us. Did she contact us or not?\n",
      "Unfortunately, she didn't make contact.\n",
      "I'm not sure if he observed it. Did he observe it or not?\n",
      "Unfortunately, he didn't observe it.\n",
      "I'm not sure if they deployed the updates. Did they deploy them or not?\n",
      "Unfortunately, they didn't deploy them.\n",
      "14 Wizard-Lesson 21-21\n",
      "  \n",
      "I'm uncertain if she'll visit the tech hub today.  \n",
      "Will she be able to visit the cybercafe today?  \n",
      "I believe she can.  \n",
      "  \n",
      "I'm not sure if he can join us for a stroll.  \n",
      "Can he accompany us?  \n",
      "I think he's able to.  \n",
      "  \n",
      "I'm unsure if she can prepare a sauce for the salad.  \n",
      "Can she create a dressing for the salad?  \n",
      "I think she's capable of doing so.  \n",
      "  \n",
      "I'm unsure if the cleaning service can tidy up the house tomorrow morning.  \n",
      "Can they clean the house tomorrow morning?  \n",
      "I don't think they can.  \n",
      "  \n",
      "I'm unsure if they will reach out to us this evening.  \n",
      "Can they contact us tonight?  \n",
      "I believe they can.  \n",
      "  \n",
      "Are they able to attend the dance together?  \n",
      "Do you think they could?  \n",
      "I think it's possible.  \n",
      "  \n",
      "Can she provide transportation to work for them?  \n",
      "Do you think she's capable of it?  \n",
      "I believe she could.  \n",
      "  \n",
      "Is it possible for the meeting to commence at 8 o'clock?  \n",
      "Do you think it could start at 8?  \n",
      "I think it's feasible.  \n",
      "  \n",
      "Can they secure the house for us?  \n",
      "Do you think they could?  \n",
      "I believe they could.  \n",
      "15 Wizard-Lesson 22-22\n",
      "The developer can assist us. \n",
      "When can the developer assist us? \n",
      "The developer can assist us at any time. \n",
      "The programmer can access the internet. \n",
      "Where can the programmer access the internet? \n",
      "The programmer can access it from the office computer. \n",
      "The team can pay for our lunch. \n",
      "When can the team pay for our lunch? \n",
      "The team can pay for it tomorrow. \n",
      "The manager can see her. \n",
      "When can the manager see her? \n",
      "The manager can see her next week. \n",
      "The designer can take our pictures. \n",
      "When can the designer take our pictures? \n",
      "The designer can take them right now. \n",
      "We could use their computer. \n",
      "When could we use it? \n",
      "I think we could use it today. \n",
      "They could take the children to the meeting. \n",
      "How could they take them? \n",
      "They could take them by car. \n",
      "They could live with us. \n",
      "How could they live with us? \n",
      "They could live with us in the summer. \n",
      "It could take months. \n",
      "How could it take months? \n",
      "It could take months if it rains. \n",
      "It could work. \n",
      "How could it work? \n",
      "It could work if we had the right person.\n",
      "16 Wizard-Lesson 23-23\n",
      "Should we leave for the office now or later?\n",
      "I believe we should leave now.\n",
      "I believe we shouldn't leave.\n",
      "Should we review the codebase tonight?\n",
      "I think we should.\n",
      "I don't think we should.\n",
      "Should he bring his spouse to the team meeting?\n",
      "Should I review the pull requests now?\n",
      "I think you should.\n",
      "I don't think you should.\n",
      "Should they await us at the hackathon venue?\n",
      "I don't think you should.\n",
      "I think you should.\n",
      "I don't think you should.\n",
      "I think you should.\n",
      "I think you should.\n",
      "I don't think you should.\n",
      "Should they wait for us at the hackathon venue?\n",
      "I think they should.\n",
      "I think they shouldn't.\n",
      "Should the project manager take minutes at the sprint planning?\n",
      "In my opinion, she should.\n",
      "I don't know why, but I think she shouldn't.\n",
      "Should he arrive at the stand-up meeting early?\n",
      "I think he should.\n",
      "In my opinion, he must arrive at the meeting early.\n",
      "Should they put in extra hours?\n",
      "I think they shouldn't.\n",
      "In my opinion, they should.\n",
      "He must work overtime if he wants to complete all his tasks.\n",
      "I think he really should put in extra hours.\n",
      "In my opinion, he should not put in extra hours.\n",
      "Should the tech lead be let go?\n",
      "I think he should not be let go.\n",
      "In my opinion, he should be let go.\n",
      "17 Wizard-Lesson 24-24\n",
      "He should check the code on the test environment.\n",
      "Why should he check the code on the test environment?\n",
      "Because that is the best place to run the tests.\n",
      "You should meet with the client tomorrow.\n",
      "Why should I meet with the client tomorrow?\n",
      "Because tomorrow is the best day for them.\n",
      "Why should I meet with the client tomorrow?\n",
      "Because tomorrow is the best day for them.\n",
      "Why should I meet with the client tomorrow?\n",
      "Because tomorrow is the best day for them.\n",
      "Why should I meet with the client tomorrow.\n",
      "Why should I meet with the client tomorrow?\n",
      "Because tomorrow is the best day for you to meet with them.\n",
      "You should run the unit tests now.\n",
      "Why should I run the unit tests now? Because this is the best time to run the tests.\n",
      "She should schedule a meeting with the team today.\n",
      "Why should she schedule a meeting with the team today?\n",
      "Because today is the best day of the week to schedule a meeting.\n",
      "You should commit your changes to the repository.\n",
      "Life should be agile.\n",
      "In your opinion, why should life be agile?\n",
      "Because life is too short.\n",
      "In my opinion, the developer should be promoted.\n",
      "Why should the developer be promoted?\n",
      "Because their performance is outstanding.\n",
      "You must fix the bug in the code.\n",
      "Why must I fix the bug in the code?\n",
      "Because it is critical and it needs to be fixed immediately.\n",
      "The developer mustn't merge the code yet.\n",
      "Why mustn't the developer merge the code yet?\n",
      "Because it hasn't been reviewed yet.\n",
      "They must deliver the project by the end of the week.\n",
      "Because the deadline is approaching.\n",
      "18 Wizard-Lesson 25-25\n",
      "The developer will communicate with the database administrator. I'm confident he will engage in conversation with him.\n",
      "If he doesn't communicate with him, who will?\n",
      "The programmer will optimize the code for efficiency. I'm certain he will optimize it well.\n",
      "If he won't optimize the code well, who will?\n",
      "The team will meet the project deadline. I'm confident they will meet it on time.\n",
      "If they won't meet the deadline, who will?\n",
      "Stephanie will deploy a well-functioning algorithm. I am certain she will.\n",
      "If she won't deploy the algorithm, who will?\n",
      "She will transfer large datasets from the cloud. I am sure she will transfer the data.\n",
      "If she won't transfer the datasets, who will?\n",
      "I will automate some processes for you. I am sure you will appreciate it. Because if you don't use the automation, who will?\n",
      "She will showcase her latest machine learning model at the conference. I am confident she will present it. Because if she doesn't bring her model, who will?\n",
      "He will debug the code efficiently. I am sure he will. Because if he doesn't debug it effectively, who will?\n",
      "He will implement the neural network by next week. I am sure he will complete the implementation. Because if he doesn't implement it, who will?\n",
      "19 Wizard-Lesson 26-26\n",
      "When will the developer upload the code to the repository?\n",
      "I hope they will do it today.\n",
      "I do too. \n",
      "When will the data scientist implement the new algorithm?\n",
      "We hope they will do it tonight.\n",
      "We do too, because it's crucial for the project.\n",
      "When will I have a sync-up with you?\n",
      "I hope we will sync-up soon.\n",
      "I do too, because we need to discuss the project.\n",
      "When will we deploy the new feature?\n",
      "I hope we will deploy it soon.\n",
      "I do too, because the users are waiting for it eagerly.\n",
      "When will they transfer the funds?\n",
      "I hope they will transfer the funds this week.\n",
      "I do too, because the project budget depends on it.\n",
      "When will they update the database schema?\n",
      "I hope they will do it this morning.\n",
      "I do too, because it's blocking our progress.\n",
      "When will the model training process start?\n",
      "I hope it will start soon.\n",
      "I do too because the deadline is approaching.\n",
      "When will the testing phase begin?\n",
      "I hope it will begin now.\n",
      "I do too, because the go-live date is near.\n",
      "When will the sprint end?\n",
      "I hope it will end before 10.\n",
      "I do too, because we have a demo at 10.\n",
      "When will we have a code review session?\n",
      "I hope we will have it soon.\n",
      "I do too, because code quality is important.\n",
      "20 Wizard-Lesson 27-27\n",
      "She would like to attend the meeting with us.\n",
      "Why don't we bring her? I think we should bring her with us.\n",
      "He would like to accompany us to the conference.\n",
      "I think we should go with him. That is a good idea.\n",
      "My supervisor would like to transport you to the office.\n",
      "Would you like to commute with us? Yes, I would. I would love to commute with you.\n",
      "He would like to have a discussion with you.\n",
      "Why should I have a discussion with him? Because he's a very insightful professional.\n",
      "She would like to obtain your contact information.\n",
      "Why should I provide her with my contact information? Because she wants to send some important updates to you.\n",
      "They would like to acquire your phone number.\n",
      "Why should I provide them with my phone number? I don't think you should share your phone number with them.\n",
      "He would love to attend a workshop with you.\n",
      "Why should I attend a workshop with him? He's the most skilled individual in the department.\n",
      "He would like to host us for a lunch meeting.\n",
      "Do you think we should have a lunch meeting with him? I think we should.\n",
      "They would like to supervise our children for us.\n",
      "Do you think we should entrust our kids to them? I think we should.\n",
      "She would like to form a professional partnership with him.\n",
      "Do you think they should form a professional partnership? I think they should.\n",
      "21 Wizard-Lesson 28-28\n",
      "The developer needs to speak with him immediately.\n",
      "Why does the developer need to speak with him?\n",
      "I'm not sure about the reason for the request.\n",
      "They are interested in relocating to the ground floor.\n",
      "What is the motivation behind their interest in living on the ground floor?\n",
      "Why do they want to reside on the ground floor?\n",
      "What drives their desire to live on the lower level?\n",
      "What's the reasoning behind their preference for the basement?\n",
      "Their choice stems from financial constraints and the unaffordability of a spacious apartment.\n",
      "He is turning 15 years old this week.\n",
      "How can you be certain he will turn 15 this week?\n",
      "It coincides with his birthday this week.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m( line )\n\u001b[1;32m     14\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m processor(text\u001b[38;5;241m=\u001b[39mline, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m         speech \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         sf\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, speech\u001b[38;5;241m.\u001b[39mnumpy(), samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     if j >0:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         break\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# if i == 0:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py:2930\u001b[0m, in \u001b[0;36mSpeechT5ForTextToSpeech.generate_speech\u001b[0;34m(self, input_ids, speaker_embeddings, attention_mask, threshold, minlenratio, maxlenratio, vocoder, output_cross_attentions, return_output_lengths)\u001b[0m\n\u001b[1;32m   2925\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2926\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2927\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe first dimension of speaker_embeddings must be either 1 or the same as batch size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2928\u001b[0m             )\n\u001b[0;32m-> 2930\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generate_speech\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2932\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminlenratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxlenratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2939\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_cross_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_output_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2941\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py:2569\u001b[0m, in \u001b[0;36m_generate_speech\u001b[0;34m(model, input_values, speaker_embeddings, attention_mask, threshold, minlenratio, maxlenratio, vocoder, output_cross_attentions, return_output_lengths)\u001b[0m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(SPEECHT5_INPUTS_DOCSTRING)\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;129m@replace_return_docstrings\u001b[39m(output_type\u001b[38;5;241m=\u001b[39mSeq2SeqSpectrogramOutput, config_class\u001b[38;5;241m=\u001b[39m_CONFIG_FOR_DOC)\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2539\u001b[0m     stop_labels: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, Seq2SeqSpectrogramOutput]:\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;124;03m    input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;124;03m        Indices of input sequence tokens in the vocabulary. The `batch_size` should be 1 currently.\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \n\u001b[1;32m   2545\u001b[0m \u001b[38;5;124;03m        Indices can be obtained using [`SpeechT5Tokenizer`]. See [`~PreTrainedTokenizer.encode`] and\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;124;03m        [`~PreTrainedTokenizer.__call__`] for details.\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m \n\u001b[1;32m   2548\u001b[0m \u001b[38;5;124;03m        [What are input IDs?](../glossary#input-ids)\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;124;03m    decoder_input_values (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_mel_bins)`):\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;124;03m        Float values of input mel spectrogram.\u001b[39;00m\n\u001b[1;32m   2551\u001b[0m \n\u001b[1;32m   2552\u001b[0m \u001b[38;5;124;03m        SpeechT5 uses an all-zero spectrum as the starting token for `decoder_input_values` generation. If\u001b[39;00m\n\u001b[1;32m   2553\u001b[0m \u001b[38;5;124;03m        `past_key_values` is used, optionally only the last `decoder_input_values` have to be input (see\u001b[39;00m\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;124;03m        `past_key_values`).\u001b[39;00m\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;124;03m    speaker_embeddings (`torch.FloatTensor` of shape `(batch_size, config.speaker_embedding_dim)`, *optional*):\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;124;03m        Tensor containing the speaker embeddings.\u001b[39;00m\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;124;03m    labels (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_mel_bins)`, *optional*):\u001b[39;00m\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;124;03m        Float values of target mel spectrogram. Spectrograms can be obtained using [`SpeechT5Processor`]. See\u001b[39;00m\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;124;03m        [`SpeechT5Processor.__call__`] for details.\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;124;03m    stop_labels (`torch.FloatTensor` of shape `(batch_size, unreduced_sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   2561\u001b[0m \u001b[38;5;124;03m        Labels for computing the stop token loss. Values are 0.0 until the end of the sequence, after which they\u001b[39;00m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;124;03m        become 1.0. The sequence length of this tensor is `config.reduction_factor` times larger than the length of\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;124;03m        the target mel spectrogram. Labels can be obtained using [`SpeechT5Processor`]. See\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m \u001b[38;5;124;03m        [`SpeechT5Processor.__call__`] for details.\u001b[39;00m\n\u001b[1;32m   2565\u001b[0m \n\u001b[1;32m   2566\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   2567\u001b[0m \n\u001b[1;32m   2568\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m-> 2569\u001b[0m \n\u001b[1;32m   2570\u001b[0m \u001b[38;5;124;03m    ```python\u001b[39;00m\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;124;03m    >>> from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan, set_seed\u001b[39;00m\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;124;03m    >>> import torch\u001b[39;00m\n\u001b[1;32m   2573\u001b[0m \n\u001b[1;32m   2574\u001b[0m \u001b[38;5;124;03m    >>> processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;124;03m    >>> model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\u001b[39;00m\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;124;03m    >>> vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m \n\u001b[1;32m   2578\u001b[0m \u001b[38;5;124;03m    >>> inputs = processor(text=\"Hello, my dog is cute\", return_tensors=\"pt\")\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m \u001b[38;5;124;03m    >>> speaker_embeddings = torch.zeros((1, 512))  # or load xvectors from a file\u001b[39;00m\n\u001b[1;32m   2580\u001b[0m \n\u001b[1;32m   2581\u001b[0m \u001b[38;5;124;03m    >>> set_seed(555)  # make deterministic\u001b[39;00m\n\u001b[1;32m   2582\u001b[0m \n\u001b[1;32m   2583\u001b[0m \u001b[38;5;124;03m    >>> # generate speech\u001b[39;00m\n\u001b[1;32m   2584\u001b[0m \u001b[38;5;124;03m    >>> speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\u001b[39;00m\n\u001b[1;32m   2585\u001b[0m \u001b[38;5;124;03m    >>> speech.shape\u001b[39;00m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;124;03m    torch.Size([16384])\u001b[39;00m\n\u001b[1;32m   2587\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2588\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2589\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   2591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py:3353\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, spectrogram)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py:3246\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m--> 310\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "File \u001b[0;32m/workspaces/speech-recognition/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_conv_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, weight: Tensor, bias: Optional[Tensor]):\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                         weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                         _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    310\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    lesson_name = row[\"Filename\"].split(\".\")[0]\n",
    "    print( i, lesson_name )\n",
    "\n",
    "    folder = f\"new_audio/{lesson_name}\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    for j, line in enumerate( row[\"Sentences_new\"].replace(\"-separator-\", \"\").split(\"\\n\")[1:] ):\n",
    "        if line != \"\":\n",
    "            print( line )\n",
    "            \n",
    "\n",
    "            inputs = processor(text=line, return_tensors=\"pt\")\n",
    "            speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "            sf.write(f\"{folder}/{j:03d}.wav\", speech.numpy(), samplerate=16000)\n",
    "\n",
    "    #     if j >0:\n",
    "    #         break\n",
    "\n",
    "    # if i == 0:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "009\n"
     ]
    }
   ],
   "source": [
    "print(f\"{9:03d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
